{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# (a) Load data and perform PCA\n",
    "portfolios_data = pd.read_csv('portfolios.csv', index_col=0, parse_dates=True)\n",
    "portfolios_data = portfolios_data.loc['199001':'201912']\n",
    "\n",
    "# Standardize the portfolio data\n",
    "portfolios_scaled = (portfolios_data - portfolios_data.mean()) / portfolios_data.std()\n",
    "\n",
    "# Perform SVD on the standardized portfolio data\n",
    "U, S, Vh = np.linalg.svd(portfolios_scaled, full_matrices=False)\n",
    "pc1 = U[:, 0]\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = (S ** 2) / (S ** 2).sum()\n",
    "\n",
    "# Scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), explained_variance_ratio[:10], 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n",
    "\n",
    "# Fraction of variation explained\n",
    "cumulative_var_exp = np.cumsum(explained_variance_ratio)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), cumulative_var_exp[:10], 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Fraction of Variation Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "# Load the returns.csv file\n",
    "returns_data = pd.read_csv('returns.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Extract the market return and risk-free rate from the returns.csv file\n",
    "market_return = returns_data['Mkt-RF'] + returns_data['RF']\n",
    "risk_free_rate = returns_data['RF']\n",
    "\n",
    "# Align the dates of the first principal component and market return\n",
    "common_dates = portfolios_data.index.intersection(market_return.index)\n",
    "pc1_aligned = pd.Series(pc1, index=portfolios_data.index).loc[common_dates]\n",
    "market_return_aligned = market_return.loc[common_dates]\n",
    "\n",
    "# Calculate the scaling factor\n",
    "scaling_factor = market_return_aligned.std() / pc1_aligned.std()\n",
    "\n",
    "# Scale the first principal component\n",
    "pc1_scaled = pc1_aligned * scaling_factor\n",
    "\n",
    "# Create index based on the position in the vector\n",
    "index = np.arange(len(pc1_scaled))\n",
    "\n",
    "# Plot the scaled first principal component and market return\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(index, pc1_scaled, label='First Principal Component (Scaled)')\n",
    "plt.plot(index, market_return_aligned, label='Market Return')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Return')\n",
    "plt.title('First Principal Component (SVD) vs Market Return')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation between the scaled first principal component and market return\n",
    "correlation = np.corrcoef(pc1_scaled, market_return_aligned)[0, 1]\n",
    "print(f\"Correlation between Scaled First Principal Component and Market Return: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b831c",
   "metadata": {},
   "source": [
    "The first principal component (PC1) obtained from the PCA on the 10 portfolios sorted by momentum has a (high) correlation of 0.97  the scaled market return. This suggests that the first principal component captures a significant portion of the variation in the market return.\n",
    "The high correlation implies that the first principal component is closely related to the \"market\" factor, In other words, the first principal component seems to be capturing the systematic risk that is common across the 10 momentum portfolios.\n",
    "CAPM would say that the expected return of an asset is determined by its beta (the asset's sensitivity to the market risk factor).\n",
    "This finding is consistent with the idea that the market factor is the dominant source of systematic risk in asset returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63383bef",
   "metadata": {},
   "source": [
    "(c) Consider the \"fraction explained\" plot from part (a)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9928fb",
   "metadata": {},
   "source": [
    "Fraction of variation explained with 10 principal components}\n",
    "The singular value decomposition (SVD) of the standardized portfolio returns matrix $X$ can be expressed as:\n",
    "\\begin{equation}\n",
    "A = U S V^T\n",
    "\\end{equation}\n",
    "where $U$ and $V$ are orthogonal matrices, and S is a diagonal matrix containing the singular values $s_i$ in descending order.\n",
    "The rank of a matrix is the maximum number of linearly independent rows or columns. In the case of the returns matrix A, which has dimensions 10 × 360 (n × m), the maximum possible rank is $min(n, m) = 10$.\n",
    "Since the returns matrix A has a maximum possible rank of 10, there can be at most 10 non-zero singular values. Each non-zero singular value corresponds to a principal component that explains a portion of the variation in the data.\n",
    "When we compute the SVD of the returns matrix A, we obtain 10 non-zero singular values, each associated with a principal component. These 10 principal components collectively explain 100% of the variation in the data.\n",
    "In other words, the 10 principal components span the entire space of the returns matrix A. By projecting the data onto these 10 principal components, we can perfectly reconstruct the original returns matrix A without any loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Convert monthly returns to cumulative returns\n",
    "returns_scaled = portfolios_data / 100\n",
    "log_returns = np.log(1 + returns_scaled)\n",
    "cumulative_returns = np.exp(log_returns.cumsum()) - 1\n",
    "\n",
    "# Standardize the cumulative returns\n",
    "scaler_cumulative = StandardScaler()\n",
    "cumulative_returns_scaled = scaler_cumulative.fit_transform(cumulative_returns)\n",
    "\n",
    "# Perform SVD on the standardized cumulative returns\n",
    "U_cumulative, S_cumulative, Vh_cumulative = np.linalg.svd(cumulative_returns_scaled, full_matrices=False)\n",
    "\n",
    "# Explained variance ratio for cumulative returns\n",
    "explained_variance_ratio_cumulative = (S_cumulative ** 2) / (S_cumulative ** 2).sum()\n",
    "\n",
    "# Fraction of variation explained for cumulative returns\n",
    "cumulative_var_exp_cumulative = np.cumsum(explained_variance_ratio_cumulative)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), cumulative_var_exp[:10], 'bo-', linewidth=2, label='Monthly Returns')\n",
    "plt.plot(range(1, 11), cumulative_var_exp_cumulative[:10], 'ro-', linewidth=2, label='Cumulative Returns')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Fraction of Variation Explained (Monthly vs Cumulative Returns)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399841c1",
   "metadata": {},
   "source": [
    "One potential explanation for why the proportion of explained variance is higher with cumulative returns(you may think of more), could be that when we take cumulative returns, we strip out some of the higher frequency idiosyncratic variation in returns. This would allow the long-term trends to be more easily captured by the principal components. The higher proportion of variance suggests that these components are better able to capture the essential long-term dynamics of the portfolio returns - though note that the monthly returns still do well.\n",
    "It may help to think of this in association with the discussion in part b about the market factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883409d0",
   "metadata": {},
   "source": [
    "1e)¶To find the number of elements needed to store the best rank-2 approximation A₂, we can use the truncated SVD formula:\n",
    "A₂ = U₂ S₂ V₂'\n",
    "where:\n",
    "U₂ is an m × 2 matrix containing the first two left singular vectors.\n",
    "S₂ is a 2 × 2 diagonal matrix containing the first two singular values.\n",
    "V₂ is an n × 2 matrix containing the first two right singular vectors.\n",
    "U₂: The matrix U₂ has dimensions m × 2, so it requires storing m × 2 = 360 × 2 = 720 elements.\n",
    "S₂: The diagonal matrix S₂ has dimensions 2 × 2, but since it is diagonal, we only need to store the two singular values. Therefore, S₂ requires storing 2 elements.\n",
    "V₂: The matrix V₂ has dimensions n × 2, so it requires storing n × 2 = 10 × 2 = 20 elements.\n",
    "In total, the number of elements needed to store the best rank-2 approximation A₂ is:\n",
    "Number of elements = Elements in U₂ + Elements in S₂ + Elements in V₂\n",
    "= 720 + 2 + 20\n",
    "= 742"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
